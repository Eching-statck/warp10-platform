//
//   Copyright 2019-2023  SenX S.A.S.
//
//   Licensed under the Apache License, Version 2.0 (the "License");
//   you may not use this file except in compliance with the License.
//   You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
//   Unless required by applicable law or agreed to in writing, software
//   distributed under the License is distributed on an "AS IS" BASIS,
//   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
//   See the License for the specific language governing permissions and
//   limitations under the License.
//

/////////////////////////////////////////////////////////////////////////////////////////
//
// D I R E C T O R Y
//
/////////////////////////////////////////////////////////////////////////////////////////

###
### M A N D A T O R Y   C O N F I G U R A T I O N
###

##
## MANDATORY - ZooKeeper server list for registering
##
directory.zk.quorum = ${zk.quorum}

##
## MANDATORY - ZooKeeper znode under which to register
##
directory.zk.znode = /zk/warp/${warp10.instance}/services

##
## MANDATORY - Number of threads to run for ingesting metadata from Kafka
##
directory.kafka.nthreads = 1

##
## MANDATORY - Partition of metadatas we focus on, format is MODULUS:REMAINDER, use 1:0 to handle all data
##
directory.partition = 1:0

##
## MANDATORY - Address on which the Directory will listen
##
directory.host = 127.0.0.1

##
## MANDATORY - 128 bits SipHash key for request fingerprinting.
## Valid formats are hex:..., base64:... or, when using OSS, wrapped:....
##
directory.psk = ${directory.hash.key}

##
## MANDATORY - Max age of signed requests in milliseconds
##
directory.maxage = 1800000

##
## MANDATORY - Boolean indicating whether or not we should initialize Directory by reading FoundationDB
##
directory.init = true

##
## MANDATORY - Boolean indicating whether or not we should store in FoundationDB metadata we get from Kafka
##
directory.store = true

##
## MANDATORY - Boolean indicating whether or not we should do deletions in FoundationDB
##
directory.delete = true

##
## MANDATORY - Boolean indicting whether or not we should register in ZK
##
directory.register = true

##
## MANDATORY - Comma separated list of Kafka brokers for the metadata cluster
##
directory.kafka.metadata.consumer.bootstrap.servers = ${kafka.metadata.bootstrap.servers}

##
## MANDATORY - Actual 'metadata' topic
##
directory.kafka.metadata.topic = ${kafka.metadata.topic}

##
## MANDATORY - Kafka group id with which to consume the metadata topic
##
directory.kafka.metadata.groupid = directory.metadata

##
## MANDATORY - Delay between synchronizations for offset commit
##
directory.kafka.metadata.commitperiod = 1000

##
## MANDATORY - Port the streaming directory service listens to
##
directory.streaming.port = 8885

##
## MANDATORY - Number of Jetty selectors for the streaming server
##
directory.streaming.selectors = 4

##
## MANDATORY - Number of Jetty acceptors for the streaming server
##
directory.streaming.acceptors = 2

##
## MANDATORY - Idle timeout for the streaming directory endpoint
##
directory.streaming.idle.timeout = 300000

##
## MANDATORY - Number of threads in Jetty's Thread Pool
##
directory.streaming.threadpool = 200

##
## MANDATORY - Path to the FoundationDB cluster file. This file needs to be readable AND writable by the
## user running the Directory instance.
##
directory.fdb.clusterfile = ${fdb.clusterfile}

##
## MANDATORY - Maximum byte size of the pending mutations list before it is flushed to FoundationDB.
## This value cannot exceed 9500000 bytes.
##
directory.fdb.metadata.pendingmutations.maxsize = 5000000

###
### O P T I O N A L   C O N F I G U R A T I O N
###
### Values shown are the default when they exist
###

##
## Number of threads to use for the initial loading of Metadata
##
#directory.init.nthreads = 4

##
## TCP Backlog applied to the streaming directory service listener
##
#directory.streaming.tcp.backlog = 0

##
## Maximum size of Jetty ThreadPool queue size (unbounded by default)
##
#directory.streaming.maxqueuesize = 400

##
## 128/192/256 bits AES key for encrypting metadata in FoundationDB.
## Valid formats are hex:..., base64:... or, when using OSS, wrapped:....
##
directory.fdb.metadata.aes = ${fdb.metadata.aes}

##
## Optional FoundationDB tenant to use.
## The tenant MUST exist.
##
#directory.fdb.tenant =

##
## Number of retries for FoundationDB transactions (defaults to 4)
##
#directory.fdb.retrylimit = 4

##
## Jetty attributes for the streaming directory
##
#directory.streaming.jetty.attribute.XXX = value
# Example to modify the maximum size of acceptable form request, to support large selector regexps for example
#directory.streaming.jetty.attribute.org.eclipse.jetty.server.Request.maxFormContentSize = 10000000

##
## 128 bits SipHash key for computing MACs. Valid formats are hex:..., base64:... or, when using OSS, wrapped:....
##
directory.kafka.metadata.mac = ${kafka.metadata.mac}

##
## 128/192/256 bits AES key for encrypting metadata in Kafka.
## Valid formats are hex:..., base64:... or, when using OSS, wrapped:....
##
#directory.kafka.metadata.aes = ${kafka.metadata.aes}

##
## Class name of directory plugin to use
##
#directory.plugin.class = directory.plugin.class =

##
## Name of attribute which will be set to the source of the metadata update
## so the plugin can process it accordingly
##
#directory.plugin.sourceattr =

##
## Activity period (in ms) to consider when flushing Metadata to HBase
## Should match ingress.activity.window unless you know what you are doing...
##
#directory.activity.window = 3600000

##
## Size of metadata cache in number of entries
##
#directory.metadata.cache.size = 1000000

##
## Maximum number of classes for which to report detailed stats in 'FINDSTATS'
##
#directory.stats.class.maxcardinality = 100

##
## Maximum number of labels for which to report detailed stats in 'FINDSTATS'
##
#directory.stats.labels.maxcardinality = 100

##
## Should we ignore the proxy settings when doing a streaming request?
##
#directory.streaming.noproxy = false

##
## Prefix used to specify custom Kafka consumer properties
##
#directory.kafka.metadata.consumer.conf.prefix =

##
## Kafka client.id to use for the metadata topic consumer
##
#directory.kafka.metadata.consumer.clientid =

##
## Strategy to adopt if consuming for the first time or if the last committed offset is past Kafka history
##
#directory.kafka.metadata.consumer.auto.offset.reset =

##
## Name of partition assignment strategy to use
##
#directory.kafka.metadata.consumer.partition.assignment.strategy =
